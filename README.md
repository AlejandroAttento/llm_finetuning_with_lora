# LLM-Parameter-Efficient-Fine-Tuning-with-LoRA
This repository provides an example of fine-tuning a large language model (LLM) using a Parameter-Efficient Fine-Tuning (PEFT) strategy with Low-Rank Adaptation (LoRA). It highlights the effectiveness of smaller models in binary classification tasks when fine-tuned appropriately. Additionally, it demonstrates how PEFT strategies enable efficient fine-tuning with minimal resources and computational overhead.

